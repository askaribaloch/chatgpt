{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client : OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def getCurrentWeather(location:str, unit:str=\"fahrenheit\")->str | dict | None:\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n",
    "    elif \"los angeles\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "    \n",
    "\n",
    "def getNickname(location:str)->str:\n",
    "    \"\"\"Get the nickname of a city\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return \"tk\"\n",
    "    elif \"los angeles\" in location.lower():\n",
    "        return \"la\"\n",
    "    elif \"paris\" in location.lower():\n",
    "        return \"py\"\n",
    "    else:\n",
    "        return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def show_json(message, obj):\n",
    "    display(message, json.loads(obj.model_dump_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta import Assistant\n",
    "\n",
    "assistant: Assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are a weather bot. Use the provided functions to answer questions.\",\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  tools=[{\n",
    "      \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"getCurrentWeather\",\n",
    "      \"description\": \"Get the weather in location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\"type\": \"string\", \"description\": \"The city and state e.g. San Francisco, CA\"},\n",
    "          \"unit\": {\"type\": \"string\", \"enum\": [\"c\", \"f\"]}\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    }\n",
    "  }, {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"getNickname\",\n",
    "      \"description\": \"Get the nickname of a city\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\"type\": \"string\", \"description\": \"The city and state e.g. San Francisco, CA\"},\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    } \n",
    "  }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_vQdPS9VVCrWOCyQgQ56eRcDr', created_at=1717418027, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n"
     ]
    }
   ],
   "source": [
    "from openai.types.beta.thread import Thread\n",
    "\n",
    "thread: Thread  = client.beta.threads.create()\n",
    "\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Request\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"How is the weather Paris?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_th3DIs5VIajlLbTcvu7lrhlv',\n",
       " 'assistant_id': None,\n",
       " 'attachments': [],\n",
       " 'completed_at': None,\n",
       " 'content': [TextContentBlock(text=Text(annotations=[], value='How is the weather Paris?'), type='text')],\n",
       " 'created_at': 1717418031,\n",
       " 'incomplete_at': None,\n",
       " 'incomplete_details': None,\n",
       " 'metadata': {},\n",
       " 'object': 'thread.message',\n",
       " 'role': 'user',\n",
       " 'run_id': None,\n",
       " 'status': None,\n",
       " 'thread_id': 'thread_vQdPS9VVCrWOCyQgQ56eRcDr'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.threads.run import Run\n",
    "\n",
    "run: Run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_9QDt51yEITPrDO8JlheoLsVx',\n",
       " 'assistant_id': 'asst_yrMUXlad6DyQ4eJoE5fdYgZ3',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': None,\n",
       " 'created_at': 1717418038,\n",
       " 'expires_at': 1717418638,\n",
       " 'failed_at': None,\n",
       " 'incomplete_details': None,\n",
       " 'instructions': 'You are a weather bot. Use the provided functions to answer questions.',\n",
       " 'last_error': None,\n",
       " 'max_completion_tokens': None,\n",
       " 'max_prompt_tokens': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-3.5-turbo-1106',\n",
       " 'object': 'thread.run',\n",
       " 'required_action': None,\n",
       " 'response_format': 'auto',\n",
       " 'started_at': None,\n",
       " 'status': 'queued',\n",
       " 'thread_id': 'thread_vQdPS9VVCrWOCyQgQ56eRcDr',\n",
       " 'tool_choice': 'auto',\n",
       " 'tools': [FunctionTool(function=FunctionDefinition(name='getCurrentWeather', description='Get the weather in location', parameters={'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state e.g. San Francisco, CA'}, 'unit': {'type': 'string', 'enum': ['c', 'f']}}, 'required': ['location']}), type='function'),\n",
       "  FunctionTool(function=FunctionDefinition(name='getNickname', description='Get the nickname of a city', parameters={'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state e.g. San Francisco, CA'}}, 'required': ['location']}), type='function')],\n",
       " 'truncation_strategy': TruncationStrategy(type='auto', last_messages=None),\n",
       " 'usage': None,\n",
       " 'temperature': 1.0,\n",
       " 'top_p': 1.0,\n",
       " 'tool_resources': {}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_functions = {\n",
    "    \"getCurrentWeather\": getCurrentWeather,\n",
    "    \"getNickname\": getNickname\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thread_vQdPS9VVCrWOCyQgQ56eRcDr'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_action .....\n",
      "requires_action .....\n",
      "Status:  requires_action\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'submit_tool_outputs'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'submit_tool_outputs': {'tool_calls': [{'id': 'call_M7mDiync7WxVWsMc5WqmCwf3',\n",
       "    'function': {'arguments': '{\"location\":\"Paris\",\"unit\":\"c\"}',\n",
       "     'name': 'getCurrentWeather'},\n",
       "    'type': 'function'}]},\n",
       " 'type': 'submit_tool_outputs'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toolCalls present:\n",
      "<function getCurrentWeather at 0x000002E24F37E200> True ================================================================\n",
      "[{'tool_call_id': 'call_M7mDiync7WxVWsMc5WqmCwf3', 'output': '{\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"}'}] >>>>>\n",
      "queued .....\n",
      "Run is queued. Waiting...\n",
      "completed .....\n",
      "completed...........logic\n",
      "Assistant: The current temperature in Paris is 22Â°C.\n",
      "\n",
      "User: How is the weather Paris?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "  # Loop until the run completes or requires action\n",
    "while True:\n",
    "    runStatus = client.beta.threads.runs.retrieve(thread_id=thread.id,\n",
    "                                                  run_id=run.id)\n",
    "    # Add run steps retrieval here for debuging\n",
    "    run_steps = client.beta.threads.runs.steps.list(thread_id=thread.id, run_id=run.id)\n",
    "    # show_json(\"Run Steps:\", run_steps)\n",
    "    print(runStatus.status ,'.....')\n",
    "\n",
    "    # This means run is making a function call   \n",
    "    if runStatus.status == \"requires_action\":\n",
    "        print(runStatus.status ,'.....')\n",
    "        print(\"Status: \", \"requires_action\")\n",
    "        show_json(\"submit_tool_outputs\", runStatus.required_action)\n",
    "        if runStatus.required_action.submit_tool_outputs and runStatus.required_action.submit_tool_outputs.tool_calls:\n",
    "            print(\"toolCalls present:\")\n",
    "            toolCalls = runStatus.required_action.submit_tool_outputs.tool_calls\n",
    "\n",
    "            tool_outputs = []\n",
    "            for toolcall in toolCalls:\n",
    "                function_name = toolcall.function.name\n",
    "                function_args = json.loads(toolcall.function.arguments)\n",
    "                \n",
    "                if function_name in available_functions:\n",
    "                    \n",
    "                    \n",
    "                    function_to_call = available_functions[function_name]\n",
    "                    print(function_to_call,function_to_call.__name__==\"getCurrentWeather\",\"================================================================\")\n",
    "                  \n",
    "                    if function_to_call.__name__ == \"getCurrentWeather\":\n",
    "                        \n",
    "                        response = function_to_call(\n",
    "                        location=function_args.get(\"location\"),\n",
    "                        unit=function_args.get(\"unit\")\n",
    "                        )\n",
    "                        \n",
    "                        \n",
    "                        tool_outputs.append({\n",
    "                                  \"tool_call_id\": toolcall.id,\n",
    "                                  \"output\": response\n",
    "                              })\n",
    "                    \n",
    "                    elif function_to_call.__name__ == \"getNickname\":\n",
    "                        response = function_to_call(\n",
    "                          location=function_args.get(\"location\")\n",
    "                          )\n",
    "                        tool_outputs.append({\n",
    "                          \"tool_call_id\": toolcall.id,\n",
    "                          \"output\": response,\n",
    "                              })\n",
    "            print(tool_outputs,\">>>>>\") \n",
    "            # Submit tool outputs and update the run\n",
    "            client.beta.threads.runs.submit_tool_outputs(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id,\n",
    "                tool_outputs=tool_outputs)\n",
    "      \n",
    "    elif runStatus.status == \"completed\":\n",
    "        # List the messages to get the response\n",
    "        print(\"completed...........logic\")\n",
    "        messages: list[message] = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        for message in messages.data:\n",
    "            role_label = \"User\" if message.role == \"user\" else \"Assistant\"\n",
    "            message_content = message.content[0].text.value\n",
    "            print(f\"{role_label}: {message_content}\\n\")\n",
    "        break  # Exit the loop after processing the completed run\n",
    "\n",
    "    elif run.status == \"failed\":\n",
    "      print(\"Run failed.\")\n",
    "      break\n",
    "\n",
    "    elif run.status in [\"in_progress\", \"queued\"]:\n",
    "      print(f\"Run is {run.status}. Waiting...\")\n",
    "      time.sleep(5)  # Wait for 5 seconds before checking again\n",
    "\n",
    "    else:\n",
    "      print(f\"Unexpected status: {run.status}\")\n",
    "      break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
